{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298e9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-09 16:53:59--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.2’\n",
      "\n",
      "input.txt.2         100%[===================>]   1.06M  1.07MB/s    in 1.0s    \n",
      "\n",
      "2023-07-09 16:54:00 (1.07 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3f723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e1e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece3e77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text len:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"Text len: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201c0ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af084712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3565e",
   "metadata": {},
   "source": [
    "### Tokenize \n",
    "Convert sequence of text into some sequence of integers.  We are building a character level language model here.  \n",
    "\n",
    "tiktoken: sub word encoding used in practice.  Here we're using a character level encoding for simplicity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4747be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 56, 43, 43, 58, 47, 52, 45, 57, 1, 43, 39, 56, 58, 46, 50, 47, 52, 45, 57, 2]\n",
      "Greetings earthlings!\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers and back\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Simple encoder and decoder functions\n",
    "def encode(input_string):\n",
    "    return [stoi[char] for char in input_string]\n",
    "\n",
    "def decode(input_tokens):\n",
    "    return ''.join([itos[token] for token in input_tokens])\n",
    "\n",
    "print(encode(\"Greetings earthlings!\"))\n",
    "print(decode(encode(\"Greetings earthlings!\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f335197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Shakespeare\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990f767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab5facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split on the data\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f23899",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Sample random chunks from the training set, and train the chunks at a time.  They should have some maximum length (block size).  \n",
    "\n",
    "Simultaneously train to make predictions at every one of these positions.  \n",
    "\n",
    "Batch dimension - multiple chunks of text that are stacked up together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ed4be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2163e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is: 47\n",
      "when input is F the target is: i\n",
      "when input is tensor([18, 47]) the target is: 56\n",
      "when input is Fi the target is: r\n",
      "when input is tensor([18, 47, 56]) the target is: 57\n",
      "when input is Fir the target is: s\n",
      "when input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "when input is Firs the target is: t\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "when input is First the target is:  \n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "when input is First  the target is: C\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "when input is First C the target is: i\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n",
      "when input is First Ci the target is: t\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] # Inputs to the transformer\n",
    "y = train_data[1:block_size + 1] # Targets (which are offset by 1)\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is: {target}\")\n",
    "    print(f\"when input is {decode(context.numpy())} the target is: {decode(target.numpy().reshape(1,))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3521a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting points for each block:  tensor([29535, 38737, 81972, 56048])\n",
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
      "        [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
      "        [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
      "        [ 0, 32, 46, 43, 56, 43,  1, 42]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n",
      "-------\n",
      "when input is tensor([6]) the target is: 1\n",
      "when input is tensor([6, 1]) the target is: 52\n",
      "when input is tensor([ 6,  1, 52]) the target is: 53\n",
      "when input is tensor([ 6,  1, 52, 53]) the target is: 58\n",
      "when input is tensor([ 6,  1, 52, 53, 58]) the target is: 1\n",
      "when input is tensor([ 6,  1, 52, 53, 58,  1]) the target is: 58\n",
      "when input is tensor([ 6,  1, 52, 53, 58,  1, 58]) the target is: 47\n",
      "when input is tensor([ 6,  1, 52, 53, 58,  1, 58, 47]) the target is: 50\n",
      "when input is tensor([6]) the target is: 1\n",
      "when input is tensor([6, 1]) the target is: 54\n",
      "when input is tensor([ 6,  1, 54]) the target is: 50\n",
      "when input is tensor([ 6,  1, 54, 50]) the target is: 39\n",
      "when input is tensor([ 6,  1, 54, 50, 39]) the target is: 52\n",
      "when input is tensor([ 6,  1, 54, 50, 39, 52]) the target is: 58\n",
      "when input is tensor([ 6,  1, 54, 50, 39, 52, 58]) the target is: 43\n",
      "when input is tensor([ 6,  1, 54, 50, 39, 52, 58, 43]) the target is: 58\n",
      "when input is tensor([1]) the target is: 58\n",
      "when input is tensor([ 1, 58]) the target is: 46\n",
      "when input is tensor([ 1, 58, 46]) the target is: 47\n",
      "when input is tensor([ 1, 58, 46, 47]) the target is: 57\n",
      "when input is tensor([ 1, 58, 46, 47, 57]) the target is: 1\n",
      "when input is tensor([ 1, 58, 46, 47, 57,  1]) the target is: 50\n",
      "when input is tensor([ 1, 58, 46, 47, 57,  1, 50]) the target is: 47\n",
      "when input is tensor([ 1, 58, 46, 47, 57,  1, 50, 47]) the target is: 60\n",
      "when input is tensor([0]) the target is: 32\n",
      "when input is tensor([ 0, 32]) the target is: 46\n",
      "when input is tensor([ 0, 32, 46]) the target is: 43\n",
      "when input is tensor([ 0, 32, 46, 43]) the target is: 56\n",
      "when input is tensor([ 0, 32, 46, 43, 56]) the target is: 43\n",
      "when input is tensor([ 0, 32, 46, 43, 56, 43]) the target is: 1\n",
      "when input is tensor([ 0, 32, 46, 43, 56, 43,  1]) the target is: 42\n",
      "when input is tensor([ 0, 32, 46, 43, 56, 43,  1, 42]) the target is: 53\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # Number of independent sequences yt process in parallel\n",
    "block_size = 8 # Maximum context length for the predictions \n",
    "\n",
    "def get_batch(split): # train or validation split\n",
    "    \"\"\"Generate a small batch of data from inputs x and targets y.\"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # batch_size random sequence starting points\n",
    "    print(\"Random starting points for each block: \", ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(train_data)\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"-------\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context} the target is: {target}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c549b75",
   "metadata": {},
   "source": [
    "### Bigram Language Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25d58a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c64cfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9211,  1.5433, -0.3676, -0.7483,  1.0101,  0.1215,  0.1584,  1.1340,\n",
       "         -1.1539, -0.2984],\n",
       "        [ 1.1490,  0.1812,  0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,\n",
       "         -0.7296, -1.5580]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understand nn.Embedding better \n",
    "\n",
    "# Embedding with 3 lookup values, each with an embedding dim of 10\n",
    "test_emb = nn.Embedding(3,10)\n",
    "# Create a tensor to use with that lookup\n",
    "test_tensor = torch.tensor([1, 2], dtype=torch.long)\n",
    "test_emb(test_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "689972da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8846e+00,  1.6696e-01,  4.5862e-01, -1.7662e+00,  5.8599e-01,\n",
      "          5.8728e-01,  2.8607e-01,  3.1096e-01, -6.5376e-01, -6.5763e-01,\n",
      "          3.1845e-01, -5.4959e-01, -1.4649e+00, -5.5769e-01, -6.9393e-01,\n",
      "          1.3035e+00, -4.5013e-01,  1.3471e+00,  1.6910e+00, -1.2445e-01,\n",
      "         -1.6824e+00,  1.1346e+00, -8.2384e-02,  1.0517e+00,  6.7789e-01,\n",
      "          3.0665e-01, -7.4723e-01,  7.4349e-01,  8.8766e-01, -3.2742e-01,\n",
      "          7.8394e-02, -1.5297e+00, -2.9122e-01, -1.1395e-01, -3.1367e-01,\n",
      "         -6.2931e-01,  1.1385e+00, -1.1347e+00,  1.7053e-01,  1.2249e+00,\n",
      "         -2.3454e-01, -1.0572e+00, -6.5427e-01,  1.5909e+00, -6.9949e-01,\n",
      "          2.0437e+00, -1.6563e-01, -5.6280e-02,  2.3412e+00, -2.7234e+00,\n",
      "          5.0967e-01, -8.1447e-01, -2.4604e-01, -9.7419e-01, -1.8692e-01,\n",
      "         -1.5755e-01, -2.1867e-01, -1.3519e+00, -5.7281e-02, -1.8540e+00,\n",
      "         -1.3849e+00,  6.5883e-01, -7.2578e-01,  1.4448e-01,  1.6632e-01],\n",
      "        [ 7.5070e-01,  9.1317e-01, -1.7277e+00,  1.3055e+00,  8.4746e-01,\n",
      "          7.7426e-02,  6.2986e-01, -1.2867e+00, -6.8748e-01,  2.1382e+00,\n",
      "          5.1141e-01,  1.2191e+00,  9.7527e-02, -9.7859e-01,  1.7955e+00,\n",
      "          1.3915e+00,  1.0785e+00, -6.1495e-01, -4.5885e-01,  5.6748e-01,\n",
      "          9.5883e-02, -1.5700e+00,  1.1169e+00,  5.1965e-01, -1.2423e+00,\n",
      "         -9.6182e-01, -8.4998e-02,  1.1854e-01,  1.4639e-01,  2.5362e-01,\n",
      "         -3.1187e-01, -4.5604e-01,  6.4407e-01,  6.0728e-01,  1.2397e+00,\n",
      "          7.3249e-01, -4.7898e-01, -3.3961e-01, -2.7416e-01, -7.4689e-01,\n",
      "         -5.8324e-01,  3.6988e-01, -5.5563e-01, -3.9828e-01,  3.6205e-01,\n",
      "         -8.8267e-01,  1.3537e-02, -3.0574e-01, -3.0384e-02,  8.2161e-01,\n",
      "          3.8670e-04, -4.4742e-01, -3.3411e-01,  1.6018e+00,  6.1587e-01,\n",
      "         -1.8648e+00, -9.7773e-01,  6.3224e-02, -4.5483e-01, -4.1474e-01,\n",
      "         -8.6276e-01,  1.7567e-01, -8.0510e-01, -1.1624e+00,  4.2716e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[0.0016, 0.0124, 0.0165, 0.0018, 0.0188, 0.0188, 0.0139, 0.0143, 0.0054,\n",
      "         0.0054, 0.0144, 0.0060, 0.0024, 0.0060, 0.0052, 0.0385, 0.0067, 0.0402,\n",
      "         0.0567, 0.0092, 0.0019, 0.0325, 0.0096, 0.0299, 0.0206, 0.0142, 0.0050,\n",
      "         0.0220, 0.0254, 0.0075, 0.0113, 0.0023, 0.0078, 0.0093, 0.0076, 0.0056,\n",
      "         0.0326, 0.0034, 0.0124, 0.0356, 0.0083, 0.0036, 0.0054, 0.0513, 0.0052,\n",
      "         0.0807, 0.0089, 0.0099, 0.1086, 0.0007, 0.0174, 0.0046, 0.0082, 0.0039,\n",
      "         0.0087, 0.0089, 0.0084, 0.0027, 0.0099, 0.0016, 0.0026, 0.0202, 0.0051,\n",
      "         0.0121, 0.0123],\n",
      "        [0.0221, 0.0260, 0.0019, 0.0385, 0.0243, 0.0113, 0.0196, 0.0029, 0.0052,\n",
      "         0.0884, 0.0174, 0.0353, 0.0115, 0.0039, 0.0628, 0.0419, 0.0306, 0.0056,\n",
      "         0.0066, 0.0184, 0.0115, 0.0022, 0.0318, 0.0175, 0.0030, 0.0040, 0.0096,\n",
      "         0.0117, 0.0121, 0.0134, 0.0076, 0.0066, 0.0198, 0.0191, 0.0360, 0.0217,\n",
      "         0.0065, 0.0074, 0.0079, 0.0049, 0.0058, 0.0151, 0.0060, 0.0070, 0.0150,\n",
      "         0.0043, 0.0106, 0.0077, 0.0101, 0.0237, 0.0104, 0.0067, 0.0075, 0.0517,\n",
      "         0.0193, 0.0016, 0.0039, 0.0111, 0.0066, 0.0069, 0.0044, 0.0124, 0.0047,\n",
      "         0.0033, 0.0160]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[45],\n",
      "        [15]])\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "print(m(test_tensor)[0])\n",
    "print(F.softmax(m(test_tensor)[0], dim=-1))\n",
    "print(torch.multinomial(F.softmax(m(test_tensor)[0], dim=-1), num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28f7681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
      "        [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
      "        [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
      "        [ 0, 32, 46, 43, 56, 43,  1, 42]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbdd4b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n"
     ]
    }
   ],
   "source": [
    "# yb is offset by one compared to xb - we are predicting yb given xb with the bigram model\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dd451c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3, 65])\n"
     ]
    }
   ],
   "source": [
    "test_emb = nn.Embedding(vocab_size, vocab_size)\n",
    "test_x = torch.tensor([[1, 2, 3],\n",
    "                       [3, 4, 5]])\n",
    "print(test_x)\n",
    "\n",
    "print(test_emb(test_x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a36cab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.4913, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\" Forward pass. \n",
    "        \n",
    "        This is an extremely simple model currently, where the embedding is used\n",
    "        directly as an input into softmax to create an array of probabilities.  So the \n",
    "        embedding dimension must be equal to the vocab size since the emedding values itself\n",
    "        are just the predictions.  So the model is taking each character and determining what\n",
    "        the most likely next character is, trained of the offset by one x and y values.\"\"\"\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        # We are ONLY using the embedding as the logits directly.  \n",
    "        # \n",
    "        logits = self.token_embedding_table(idx) # (B,T,C) - (Batch (4), Time (8), Channel(65))\n",
    "        \n",
    "        # Evaluate the loss (compare logits to the next character (targets))\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else: \n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C) # Stack the time pieces for each batch on top of each other batch\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"Generate new tokens on top of the existing T tokens.\"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Use the forward step to get predictions\n",
    "            logits, loss = self(idx) # Don't need loss\n",
    "            #print(\"logit shape before: \", logits.shape)\n",
    "            # Focus only on the last time step - this is what comes next actually.  \n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # use softmax to get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution (we pick a random next character but weighted by modeled probability)?\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "# Test forward pass for one batch \n",
    "logits, loss = m(xb, yb)\n",
    "# Returns the batch size, block size, and embedding dimensionality\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "# Start with a single 0 (newline char)\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "# Use the (currently untrained) model to generate new characters\n",
    "print(decode(m.generate(idx, 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf629b01",
   "metadata": {},
   "source": [
    "### Now train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4ff0f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # Number of independent sequences yt process in parallel\n",
    "block_size = 8 # Maximum context length for the predictions \n",
    "\n",
    "def get_batch(split): # train or validation split\n",
    "    \"\"\"Generate a small batch of data from inputs x and targets y.\"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # batch_size random sequence starting points\n",
    "    # print(\"Random starting points for each block: \", ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "59ff07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n"
     ]
    }
   ],
   "source": [
    "print(xb.shape)\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d05e826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split): # train or validation split\n",
    "    \"\"\"Generate a small batch of data from inputs x and targets y.\"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # batch_size random sequence starting points\n",
    "    # print(\"Random starting points for each block: \", ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ecd41e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tiny = train_data #[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1e50001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       4,       8, ..., 1003840, 1003844, 1003848])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(train_data_tiny))\n",
    "np.arange(0, len(train_data_tiny)-batch_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "644083d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d8bab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "317a60a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 0.000500\n",
      "Epoch [1/6], Loss: 2.8814, Execution time: 21.5839\n",
      "Current learning rate: 0.000325\n",
      "Epoch [2/6], Loss: 2.4629, Execution time: 20.8806\n",
      "Current learning rate: 0.000211\n",
      "Epoch [3/6], Loss: 2.4614, Execution time: 22.0986\n",
      "Current learning rate: 0.000137\n",
      "Epoch [4/6], Loss: 2.4590, Execution time: 20.7807\n",
      "Current learning rate: 0.000089\n",
      "Epoch [5/6], Loss: 2.4593, Execution time: 20.7379\n",
      "Current learning rate: 0.000058\n",
      "Epoch [6/6], Loss: 2.4568, Execution time: 20.0069\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "# Larger batch size is faster (when using gpu at least)\n",
    "batch_size = 128 # Number of independent sequences yt process in parallel\n",
    "block_size = 8 # Maximum context length for the predictions \n",
    "learning_rate = 0.0005\n",
    "num_epochs = 6\n",
    "\n",
    "device = \"cuda\" # cuda, mps, or cpu\n",
    "\n",
    "# Set up the model and optimizer\n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "batch_starts = np.arange(0, len(train_data_tiny)-batch_size, batch_size)\n",
    "batch_starts_val = np.arange(0, len(val_data)-batch_size, batch_size)\n",
    "lambda1 = lambda epoch: 0.65 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "# Iterate through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    \n",
    "    # Iterate through batches\n",
    "    for batch_start in batch_starts:\n",
    "        xb, yb = get_batch(train_data_tiny[batch_start:])\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        # forward pass \n",
    "        logits, loss = model(xb, yb)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        # Backward pass \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    total_loss = sum(batch_losses)/len(batch_losses)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print training progress\n",
    "    # This is batch loss for the most recent batch only (which isn't that meaningful).  \n",
    "    # Need to add in validation loss to make this more reasonable \n",
    "    # That's why loss is all over the place \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    #get_batch(train_data_tiny[batch_start:])\n",
    "    #val_logits, val_loss = model(x_val, y_val)\n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Execution time: {epoch_time:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3a953",
   "metadata": {},
   "source": [
    "Single epoch time with MPS: 208.6561, 13.0687  \n",
    "Single epoch time without MPS: 2.8049, 2.8232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d1803a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n",
      "\n",
      "\n",
      "CEThef brid owindake on, bthe aiset bube t e.\n",
      "SThr-d my dalatanss:\n",
      "Whitharu w he, t.\n",
      "Par dilasoate ar ce my.\n",
      "\n",
      "Hastarom orou wabuts, tof isth bot mil ndill, ath iree:\n",
      "Inghin lat Heridrovets, and t n \n"
     ]
    }
   ],
   "source": [
    "# Test the trained model - it's now outputting something that seems a little more like shakespeare\n",
    "# Start with a single 0 (newline char)\n",
    "idx = torch.zeros((1, 1), dtype=torch.long).to(device)\n",
    "# Alternative, start with a specific charater(s)\n",
    "# Bigram model is only using this by itself.  \n",
    "idx = torch.tensor([[51, 39, 62, 0]]).to(device)\n",
    "# Use the (currently untrained) model to generate new characters\n",
    "print(decode(model.generate(idx, 200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da51cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94be5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf8cef",
   "metadata": {},
   "source": [
    "### The mathematical trick in self attention\n",
    "\n",
    "Toy example\n",
    "Goal: calculate the average of the current + all previous tokens for token t in the sequence\n",
    "Averaging all the contexts is a very simple form of aggregating them.  \n",
    "\n",
    "The 'average' use is just a very simple way of two tokens communicating together - it could also be dot product of the embeddings of the two tokens (which is what we will need for attention).  \n",
    "\n",
    "This will be key to an efficient implementation of self attention.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe01487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "520b7206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 8 2\n",
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "# X bag of words \n",
    "# Innefficient for loop implementation to start.  \n",
    "print(B, T, C)\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        #print(xprev)\n",
    "        #print(torch.mean(xprev, 0))\n",
    "        xbow[b, t] = torch.mean(xprev, 0) # Take the mean of the row vectors (outputs one average row vector 1xC)\n",
    "print(xbow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c618011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3488, -0.1396],\n",
       "        [ 0.2858,  0.9651],\n",
       "        [-2.0371,  0.4931],\n",
       "        [ 1.4870,  0.5910],\n",
       "        [ 0.1260, -1.5627],\n",
       "        [-1.1601, -0.3348],\n",
       "        [ 0.4478, -0.8016],\n",
       "        [ 1.5236,  2.5086]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd5f65b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5585cca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3488, -0.1396],\n",
       "        [ 0.8173,  0.4127],\n",
       "        [-0.1342,  0.4395],\n",
       "        [ 0.2711,  0.4774],\n",
       "        [ 0.2421,  0.0694],\n",
       "        [ 0.0084,  0.0020],\n",
       "        [ 0.0712, -0.1128],\n",
       "        [ 0.2527,  0.2149]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb3774a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651]])\n",
      "tensor([0.8173, 0.4127])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "x_prev = x[1, :2]\n",
    "print(x_prev)\n",
    "print(torch.mean(x_prev, 0)) # Mean across a single axis (horizontal is compressed)\n",
    "# This is a feature vector that summarizes the vectors (poorly summarized with mean). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ff17c",
   "metadata": {},
   "source": [
    "**Vectorization of the process with a simple example**\n",
    "\n",
    "The aggregate function here is not the dot product from the book, but instead a simple average.  The average is accomplished by dotting a lower triangular matrix with the input data.  \n",
    "\n",
    "b is the x values here effectively, where each column is a vector of features.\n",
    "\n",
    "\n",
    "B, T, C is batch, time, channels\n",
    "\n",
    "Batch is a random starting point in our full sequence from which we will pull a block.  \n",
    "Each block has a size which termines how many consecutive tokens we use (the time dimension)\n",
    "Channel is the dimension of the embedding representing the token.  \n",
    "\n",
    "\n",
    "So the process of averaging is averaging the token with other tokens up to that point in the sequence to represent the token as the average of it + all before it in the sequence (so the first token embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ba79a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True) # this turns it from sum to average.  \n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46770dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize this now to make much more efficient. \n",
    "# Lower triangular matrix with each value 1/ the row value\n",
    "# Multiplying by this will take the average of the columns up to that point, which is what we want. \n",
    "wei = torch.tril(torch.ones((T, T)))\n",
    "# scaling_factor = torch.tensor([1/(i + 1) for i in range(T)]).view(8, 1)\n",
    "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
    "# r = scaling_factor * r\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0b6f037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3961ed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized version\n",
    "# this is also applied in a batch manner - each\n",
    "# Batch multiply in pytorch.  \n",
    "xbow2 = wei @ x\n",
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b8e93d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8398e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "# Softmax version - does the same thing\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "\n",
    "wei = torch.tril(torch.zeros((T, T)))\n",
    "# This method effectively removes all future knowledge when training. \n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# When we move to using attention to connect these, then softmax is normalizing the impact of each previous token on future ones.  \n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei)\n",
    "xbow3 = wei @ x\n",
    "print(xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e919930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4864ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 3.]])\n",
      "tensor([[ 8.,  0.,  0.],\n",
      "        [ 8.,  8.,  0.],\n",
      "        [10., 10., 13.]])\n",
      "tensor([[9.9933e-01, 3.3524e-04, 3.3524e-04],\n",
      "        [4.9992e-01, 4.9992e-01, 1.6770e-04],\n",
      "        [4.5279e-02, 4.5279e-02, 9.0944e-01]])\n",
      "tensor([[0.9990, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.9090]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.9980, 1.9980],\n",
       "        [2.0000, 2.0000],\n",
       "        [1.9980, 2.9070]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention examples from the book \n",
    "# 1. Just dot product\n",
    "# 2. Weight projection of xi and xj dot product together\n",
    "# The channel dimension is the token embedding dimension.  \n",
    "# Single batch example - for the bigger dataset batch broadcasting happens.\n",
    "\n",
    "torch.manual_seed(42)\n",
    "b = torch.tensor([[2, 2],\n",
    "                  [2, 2],\n",
    "                  [2, 3]]).float()\n",
    "\n",
    "# Lower triangle of the matrix multipled by itself (getting the required dot products)\n",
    "c = torch.tril(b @ b.T)\n",
    "# print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(F.softmax(c, dim=1))\n",
    "# Now apply softmax.  \n",
    "alpha = torch.round(F.softmax(c, dim=1), decimals=3)\n",
    "print(alpha)\n",
    "\n",
    "# instead of summing these, use dot products instead (this should actually collapse the C dim)\n",
    "# Also use softmax convert to a probability distribution\n",
    "\n",
    "\n",
    "# lastly get the predicted y at each output by dotting with x again (as Value)\n",
    "\n",
    "# Each row is embedding of the y prediction.  \n",
    "# Multiply the softmax values by b\n",
    "alpha @ b\n",
    "# each row of this resulting matrix is the output embedding for yi.  \n",
    "\n",
    "# This also needs to be converted to batch (right now this is a single sequence with len t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c01f840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a57d5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(X, wQ, wK, wV):\n",
    "    \"\"\"Take in a 2 or 3d tensor and calculate output embeddings.\"\"\"\n",
    "    \n",
    "    # Create the query, key, and value matrices\n",
    "    Q = X @ wQ\n",
    "    K = X @ wK\n",
    "    V = X @ wV\n",
    "\n",
    "    # Take the dot product with each previous matrix\n",
    "    if X.dim() == 2:\n",
    "        xdot = torch.tril(Q @ K.T)\n",
    "    elif X.dim() == 3:\n",
    "        xdot = torch.tril(Q @ torch.transpose(K, 1, 2))\n",
    "    else:\n",
    "        raise Exception(\"X must be a 2 or 3d tensor\")\n",
    "    \n",
    "    # Normalize by the square root of the input dim\n",
    "    xdot = xdot/math.sqrt(X.shape[-1])\n",
    "    \n",
    "    # Softmax to get weights of each previous element \n",
    "    alpha = torch.round(F.softmax(xdot, dim=1), decimals=4)\n",
    "    \n",
    "    # Multiply by X again to get a matrix with Y (each row is dim C)\n",
    "    Y = alpha @ V\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "94cc68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(C):\n",
    "    \"\"\"Create the traininable weight matrices for the query, key and value projections.\"\"\"\n",
    "\n",
    "    wQ = torch.rand(C, C, requires_grad=True)\n",
    "    wK = torch.rand(C, C, requires_grad=True)\n",
    "    wV = torch.rand(C, C, requires_grad=True)\n",
    "\n",
    "    return wQ, wK, wV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0b5f8e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6472, 1.8823],\n",
       "        [1.6168, 1.8487],\n",
       "        [1.8853, 2.1450]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1, 2],\n",
    "                  [1, 2],\n",
    "                  [1, 3]]).float()\n",
    "wQ, wK, wV = initialize_weights(C)\n",
    "self_attention(b, wQ, wK, wV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc384802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1826fe11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "74d39448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1006,  0.1403],\n",
       "         [ 0.0261,  0.0499],\n",
       "         [ 0.1359,  0.1793],\n",
       "         [ 0.1754,  0.2092],\n",
       "         [ 0.3358,  0.4152],\n",
       "         [-0.4072, -0.3680],\n",
       "         [ 0.1254,  0.1641],\n",
       "         [ 0.1134,  0.1936]],\n",
       "\n",
       "        [[-0.1039, -0.1525],\n",
       "         [-0.0859, -0.1089],\n",
       "         [-0.2781, -0.2161],\n",
       "         [ 0.2568,  0.1666],\n",
       "         [-0.3169, -0.4125],\n",
       "         [-0.5982, -0.6578],\n",
       "         [-0.1293, -0.1845],\n",
       "         [ 3.4596,  3.7538]],\n",
       "\n",
       "        [[-0.1941, -0.1603],\n",
       "         [-0.1215, -0.1088],\n",
       "         [-0.0170,  0.0469],\n",
       "         [-0.3917, -0.3531],\n",
       "         [-0.4301, -0.4143],\n",
       "         [-0.2932, -0.3108],\n",
       "         [-0.4479, -0.4518],\n",
       "         [-0.5846, -0.6460]],\n",
       "\n",
       "        [[ 0.2692, -0.1476],\n",
       "         [ 0.2840, -0.1397],\n",
       "         [ 0.2586, -0.0730],\n",
       "         [ 0.3872, -0.0726],\n",
       "         [ 0.2999, -0.2491],\n",
       "         [ 0.3148, -0.0325],\n",
       "         [ 1.0069,  1.1517],\n",
       "         [ 0.7146,  0.4515]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wQ, wK, wV = initialize_weights(C)\n",
    "self_attention(x, wQ, wK, wV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0670d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1040, -0.0287],\n",
       "         [ 0.0411, -0.1861],\n",
       "         [ 0.1485, -0.0067],\n",
       "         [ 0.3377,  0.0153],\n",
       "         [ 0.2950,  0.3330],\n",
       "         [-0.7128, -0.4754],\n",
       "         [ 0.1493, -0.0534],\n",
       "         [-0.6351,  1.4682]],\n",
       "\n",
       "        [[ 0.3156, -0.1855],\n",
       "         [ 0.0502, -0.0910],\n",
       "         [-1.7947,  0.2722],\n",
       "         [ 0.6812, -0.0133],\n",
       "         [ 0.0991, -0.9941],\n",
       "         [-0.6061, -0.2765],\n",
       "         [ 0.2010, -0.4988],\n",
       "         [ 3.0755,  3.5064]],\n",
       "\n",
       "        [[-0.1896, -0.0851],\n",
       "         [ 0.0982, -0.0334],\n",
       "         [-0.0429,  0.2894],\n",
       "         [-0.5442, -0.2200],\n",
       "         [-0.4381, -0.3440],\n",
       "         [ 0.1440, -1.1734],\n",
       "         [-0.9201,  0.1940],\n",
       "         [-0.5195, -0.4621]],\n",
       "\n",
       "        [[ 0.2870, -0.0396],\n",
       "         [ 0.3054, -0.0270],\n",
       "         [-1.3132,  2.0872],\n",
       "         [ 5.0859, -2.5198],\n",
       "         [ 1.5595, -1.2203],\n",
       "         [ 0.3539, -0.0756],\n",
       "         [ 0.7320,  1.0552],\n",
       "         [ 1.8991, -0.5725]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7175669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0067, 0.9933],\n",
       "        [0.1065, 0.1065, 0.7870]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(F.softmax(torch.tensor([[47, 56, 61],\n",
    "                        [3, 3, 5]]).float(), dim=1), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "842c4e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 5.],\n",
       "         [3., 3., 3.]]),)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2, 5],\n",
    "                        [3, 3, 3]]).float(),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ecc512",
   "metadata": {},
   "source": [
    "### Test M1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bde8bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11473331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6527948340000194"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "x = torch.ones(5000, device=\"mps\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d959ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24565041699997892"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [18]: # toy example cpu\n",
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "\n",
    "x = torch.ones(5000, device=\"cpu\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7185f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grocery local specialty'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"Grocery - Local/Specialty\"\n",
    "' '.join(re.sub('[^a-zA-Z0-9\\n\\.]', ' ', text).split()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery local specialty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch_venv",
   "language": "python",
   "name": ".pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
